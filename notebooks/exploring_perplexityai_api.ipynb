{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ðŸš€ **Exploring Perplexity API Functionality**\n",
    "\n",
    "This notebook aims to explore Perplexity API functionalities. [pplx-api](https://docs.perplexity.ai/) is a recent\n",
    "\n",
    "## ðŸ¤” **About Perplexity AI**\n",
    "\n",
    "[Perplexity AI](https://www.perplexity.ai/) is an AI-powered search engine and chatbot that uses advanced natural language processing tequniques to provide users with accurate and up-to-date information on various topics. It is designed to search the web in real-time and offer information on a wide range of subjects. Some key features and capabilities of Perplexity AI include:\n",
    "\n",
    "- 1ï¸âƒ£ **Answer Engine**: Perplexity AI focuses on advancing how people [discover](https://www.perplexity.ai/discover) and share information by providing ready-made answers to users' questions and citing sources in real-time.\n",
    "\n",
    "- 2ï¸âƒ£ **Multifaceted Applications**: Perplexity AI is versatile and can assist various professions, such as researchers, writers, artists, musicians, and programmers, in tasks like answering questions, generating text, writing creative content, and summarizing text.\n",
    "\n",
    "- 3ï¸âƒ£ **Accuracy**: The AI uses natural language processing and machine learning techniques to analyze text data, providing an in-depth analysis and generating fresh concepts, resulting in accurate answers and information.\n",
    "\n",
    "- 4ï¸âƒ£ **User-friendly Interface**: Perplexity AI is available on the web and as an app for iPhone users, making it easily accessible to a wide range of users.\n",
    "\n",
    "Perplexity AI was founded in 2022 by Andy Konwinski, Aravind Srinivas, Denis Yarats, and Johnny Ho, who have experience working with large language models at Google AI.\n",
    "\n",
    "\n",
    "## ðŸ“° **Recent releases**\n",
    "\n",
    "Perplexity AI recently introduced its [pplx-api](https://docs.perplexity.ai/), which allows developers to access the company's AI models and other resources through a REST API. The API is designed to work with various large language models:\n",
    "\n",
    "| Model Name              | Context Length | Model Type        |\n",
    "|-------------------------|-----------------|-------------------|\n",
    "| codellama-34b-instruct  | 16384           | Chat Completion  |\n",
    "| llama-2-70b-chat        | 4096            | Chat Completion  |\n",
    "| mistral-7b-instruct     | 4096 â¬†**\\***        | Chat Completion  |\n",
    "| pplx-7b-chat            | 8192            | Chat Completion  |\n",
    "| pplx-70b-chat           | 4096            | Chat Completion  |\n",
    "| pplx-7b-online          | 4096            | Chat Completion  |\n",
    "| pplx-70b-online         | 4096            | Chat Completion  |\n",
    "\n",
    "\\* as reported on the ðŸ—ºï¸ [roadmap](https://docs.perplexity.ai/docs/feature-roadmap) the context length of Mistral 7b will be extended to 32K tokens.*\n",
    "\n",
    "### ðŸ¤– Models Details\n"
   ],
   "metadata": {
    "id": "8rx6ZjAdA6ID"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EqiRcQg_ZgS",
    "outputId": "a9848898-fcb2-4c31-ddcd-902693d24cf4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting ipython-autotime\n",
      "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
      "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
      "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m6.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.41)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.10)\n",
      "Installing collected packages: jedi, ipython-autotime\n",
      "Successfully installed ipython-autotime-0.3.2 jedi-0.19.1\n",
      "time: 1.57 ms (started: 2023-12-01 13:55:31 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from enum import Enum\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Useful placeholders\n",
    "\n",
    "# PerplexityAI's API endpoint to access generative models\n",
    "URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "# Is it possibile to specify some parameters for the output generation of each model\n",
    "MAX_TOKENS = 1500\n",
    "TEMPERATURE = 0\n",
    "TOP_P = 1\n",
    "FREQUENCY_PENALTY = 1.5"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMgNqnX_nvbx",
    "outputId": "0f0525bf-e986-475b-8875-2ec63c02b948"
   },
   "execution_count": 86,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 524 Âµs (started: 2023-12-01 13:55:34 +00:00)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Available models from PerplexityAI API\n",
    "\n",
    "class AvailablePPLXModels(Enum):\n",
    "  MISTRAL_7B: str = \"mistral-7b-instruct\"\n",
    "  PPLX_7B: str = \"pplx-7b-chat\"\n",
    "  PPLX_70B: str = \"pplx-70b-chat\"\n",
    "  PPLX_7B_ON: str = \"pplx-7b-online\"\n",
    "  PPLX_70B_ON: str = \"pplx-70b-online\"\n",
    "  LLAMA2_70B: str = \"llama-2-70b-chat\"\n",
    "  CODE_LLAMA_34B: str = \"codellama-34b-isntruct\"\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-QJiX0GoHpp",
    "outputId": "73a4dd73-d4f8-4452-8e97-94ae3f221a44"
   },
   "execution_count": 87,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 1.14 ms (started: 2023-12-01 13:55:37 +00:00)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "user_query = \"How many errors are handled by AWS Kendra Retrieve API?\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"pplx-7b-online\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "              Current date: {datetime.now().strftime(\"%A, %B %d, %Y\")}\n",
    "              You have to report the most recent information about the documentation requested by the user. Use only official documentation and be as concise as possible.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_query\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": MAX_TOKENS,\n",
    "    \"temperature\": TEMPERATURE,\n",
    "    \"top_p\": TOP_P,\n",
    "    \"frequency_penalty\": FREQUENCY_PENALTY\n",
    "}\n",
    "\n",
    "assert payload['messages'] is not None, \"You need to specify some message for the model to work!\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PyxbtrqVCTxy",
    "outputId": "da3d1eaa-57b0-4947-ca25-84761305743f"
   },
   "execution_count": 88,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 1.02 ms (started: 2023-12-01 13:55:40 +00:00)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\",\n",
    "    'authorization': f\"Bearer {userdata.get('PPLXAI_API_TOKEN')}\",\n",
    "}\n",
    "\n",
    "assert headers['authorization'] is not None, \"You need to add an API Key to use Perplexity's API\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9WGgp3q7FZZQ",
    "outputId": "6f0fe842-67b5-4949-9b8e-5e37b912cc18"
   },
   "execution_count": 89,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 938 ms (started: 2023-12-01 13:55:42 +00:00)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "response = requests.post(URL, json=payload, headers=headers).json()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TI_p4OrdFZXi",
    "outputId": "55f1beb7-7a2e-4a03-f33e-8903eb7e99ff"
   },
   "execution_count": 90,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 3.65 s (started: 2023-12-01 13:55:45 +00:00)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Input tokens:\\t {response['usage']['prompt_tokens']}\")\n",
    "print(f\"Output tokens:\\t {response['usage']['completion_tokens']}\")\n",
    "print(f\"Total tokens:\\t {response['usage']['total_tokens']}\\n\\n\")\n",
    "\n",
    "print(f\"{response['choices'][0]['message']['content']}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DSh1wZNSqGs-",
    "outputId": "c64a87b2-8177-487e-b3f3-f638079e2aba"
   },
   "execution_count": 91,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input tokens:\t 43\n",
      "Output tokens:\t 334\n",
      "Total tokens:\t 377\n",
      "\n",
      "\n",
      "AWS Kendra Retrieve API handles several errors, some of which include:\n",
      "\n",
      "- AccessDeniedException: You do not have sufficient access to perform this action. HTTP Status Code: 400.\n",
      "- InternalServerException: An issue occurred with the internal server used for your Amazon Kendra service. Please wait a few minutes and try again, or contact Support for help. HTTP Status Code: 500.\n",
      "- ResourceNotFoundException: The resource you want to use doesn't exist. Please check you have provided the correct resource and try again. HTTP Status Code: 400.\n",
      "- ServiceQuotaExceededException: You have exceeded the set limits for your Amazon Kendra service. Please see Quotas for more information, or contact Support to inquire about an increase of limits. HTTP Status Code: 400.\n",
      "- ThrottlingException: The request was denied due to request throttling. Please reduce the number of requests and try again. HTTP Status Code: 400.\n",
      "- ValidationException: The input fails to satisfy the constraints set by the Amazon Kendra service. Please provide the correct input and try again. HTTP Status Code: 400.\n",
      "\n",
      "These errors may occur due to issues with access, server problems, resource not found, exceeding service limits, throttling, or invalid input. To handle these errors, you can use error handling best practices, such as catching the errors and providing appropriate error messages to the user or developer.\n",
      "\n",
      "time: 3.4 ms (started: 2023-12-01 13:55:52 +00:00)\n"
     ]
    }
   ]
  }
 ]
}
